---
title: "Simulation_Functions"
author: "Marios Christoforides"
date: '2022-04-25'
output:
  pdf_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---

```{r}
# knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

1. SIMULATION SETUP FUNCTIONS

Code from SimulationStudymLRC by Rodriguez Girondo

idi: Individual ID
id: Family ID
y: Survival Percentile
u: random effect
kk: number of family members


#Functions for calculation of mLRC
```{r}
library(spatstat) 

dbin.person = function(u, y, beta){
	p = exp(beta+u)/(1+exp(beta+u)) 
	fy = p^y * (1-p)^(1-y)
	fy
}

### example
dbin.person(1.0559919, 0.8517372, 1)


dbeta.mixed = function(par,Y,X){
	#Fixed dispersion parameter
	#marginal likelihood per person
	loglik = c()
  N=length(Y)
	for(i in 1:N)
		loglik[i] = log(gauss.hermite(dbin.person, mu=0, sd=exp(par[2]),  y=Y[X==i], beta=par[1]))
	  -sum(loglik)
}



  Y = as.numeric(df_perc$perc > TH_sig_expmin1)
  X = df_perc$idi
  par=c(1,1)
  dbeta.mixed(par=par,X=X,Y=Y)    

predict.fam = function(par, famnr, nsamples){
    U = rnorm(nsamples, 0, exp(par[2]))
    quantiles = sapply(U, function(u){
        exp(par[1]+u)/(1+exp(par[1]+u)) 
    })

    quantiles.ordered = quantiles[order(quantiles)]
    U.ordered = U[order(quantiles)]

    y=Y[X==famnr]

    print(table(y))
    dens.y = sapply(U.ordered, function(u) dbin.person(u, y=y, beta=par[1]))
    dens.y = dens.y / sum(dens.y)

    sum(quantiles.ordered * dens.y)
}

```

#Functions for calculation of Beta Regression Scores
```{r}
#######################################################
# Functions
#######################################################
#Percentile: Y
#Death status: Death
#B:Start follow-up
#Family ID
#Covariates: X
################################################
 ###################################
library(numDeriv)

loglik.sum = function(par, pos, Y,B,Death,Z){
  Zunique = unique(Z)
  Q = sapply(Zunique, function(q)
    log(gauss.hermite(likcluster, mu=0, sd=exp(par[pos$s]),  Y=Y[Z==q], B=B[Z==q],  Death=Death[Z==q], par=par, pos=pos))
  )
  -sum(Q)
}

betareg.mixed = function(Y,Death,B,Z){
  pos = list(beta=1, phi=2, s=3)
  par = rep(0,pos$s)
  par[pos$phi] = 1 

  est = nlminb(par, loglik.sum, Y=Y, Death=Death, B=B, Z=Z, pos=pos, control=list(trace=TRUE))$par
  
  H = hessian(loglik.sum, est, pos=pos, Y=Y, B=B,Death=Death, Z=Z)
  SE = diag(solve(H))
  
  #beta: effects covariates
  #phi: precision parameter
  #s: st. dev. random effects
  list(beta=est[pos$beta], phi=est[pos$phi], s=est[pos$s], pos=pos, estimates=data.frame(est=est, se=SE)) 
} 


likcluster = function(ranef, par, pos, Y,B, Death, prod=TRUE){
  xb = par[pos$beta] + ranef
  mu = exp(xb)/(1+exp(xb))
  phi = exp(par[pos$phi])
  
  alpha = mu*phi
  beta = (1-mu)*phi
  
  #If you are still alive, we require P(Y>y|p,q); this can be obtained from the 1-cum density function of the beta distribution
  if(prod){
    prod(
      pbeta(Y, alpha, beta)^B *
      (dbeta(Y, alpha, beta)^Death * pbeta(Y, alpha, beta, lower.tail=FALSE)^(1-Death))^(1-B))
    
  }else{
    pbeta(Y, alpha, beta)^B *
      (dbeta(Y, alpha, beta)^Death * pbeta(Y, alpha, beta, lower.tail=FALSE)^(1-Death))^(1-B)  
  }
}


#Predict for a certain family
predict.ranef = function(estimates, Yclus, Deathclus, Bclus, nsamples){
	U = rnorm(nsamples, 0, exp(estimates$s))
	
	#Estimate their conditional likelihood (given their random effect)
	dens.y = sapply(U, function(u){
	  likcluster(ranef=u, par=c(estimates$beta, estimates$phi, estimates$s), pos=estimates$pos, Y=Yclus,Death=Deathclus, B=Bclus)
	})
	
	dens.y = dens.y / sum(dens.y)
	sum(U * dens.y)
}
```

#Function for generating complete data
```{r}
library(EnvStats)
library(flexmix)
library(extraDistr)
#n = vector with number of families per family size e.g. c(100,100)
#kvec = vector with possible family sizes e.g. c(4,8)
#sigma = specification for standard deviation of random-effect

set.seed(1234)
Percentile.data_u <- function(n, kvec, sigma){
  alpha = 0.0690573905
  beta = 0.0004263967
  k.list<-lapply(1:length(n),function(i)rep(kvec[i],n[i]))
  k<-c(k.list[[1]])
  for (i in 2:length(n)){
    k<-c(k,k.list[[i]])
  }
  
  # print(k)
  k<-sample(k,length(k))
  # print(table(k))
  nn<-sum(table(k)*sort(unique(k)))
  # print(nn)
  u<- rep(rnorm(length(k), mean = 1, sd = sigma),k) # random effects
  # print(nn)
  # print(length(k))
  y = numeric()
  perc = numeric()
  for (i in 1:nn){
    y[i] = rgompertz(1, alpha*exp(u[i]), beta)
    perc[i]<-pgompertz(y[i], alpha*exp(u[i]), beta)
  }
  idi<-rep(1:nn)
  id<-rep(1:length(k),k)
  kk<-rep(k,k)
  mat.random<-data.frame(idi=idi, id=id, y=y, perc = perc, kk=kk, u=u)
  list(mat.random, aggregate( perc ~ id, mat.random, mean))
  # View(mat.random)
}

df_perc = as.data.frame(Percentile.data_u(c(100,100),c(4,8), 0.2)[1])
df_perc
# idi: Individual ID
# id: Family ID
# y: random gompertz value
# perc: survival percentile
# u: random effect
# kk: number of family members


```




#Function for generating data with right-censoring
```{r}
#c1 = 1st shape parameter
#c2 = 2nd shape parameter 
Percentile.data.cens<-function(n,kvec,sigma,c1,c2){
  k.list<-lapply(1:length(n),function(i)rep(kvec[i],n[i]))
  k<-c(k.list[[1]])
  for (i in 2:length(n)){
    k<-c(k,k.list[[i]])
  }
  
  k <- sample(k,length(k))
  nn <- sum(table(k)*sort(unique(k)))
  u <- rep(rnorm(length(k), mean = 1, sd = sigma),k) ### change random normal values using a mixture
  # p.mix defines the strength you want to give in the second part of the mixture
  y = numeric()
  perc = numeric()
  y = numeric()
  for (i in 1:nn){
    y[i] = rgompertz(1, alpha*exp(u[i]), beta)
    perc[i]<-pgompertz(y[i], alpha*exp(u[i]), beta)
  }
  
  cens = rbeta(nn, c1, c2) #this is how we generate the percentile at end of follow-up/right censoring. Still generated as beta dist. But no influenced by random-effect
  
  death = y <= cens # Death indicator: If death happens before censoring, you indicate that death has been observed
  y[y>cens] = cens[y>cens] # this is the observed percentile: death percentile or censoring percentile, whatever which occurs first

  
  idi<-rep(1:nn)
  id<-rep(1:length(k),k)
  kk<-rep(k,k)
  mat.random<-data.frame(idi=idi,id=id,y=y,cens=cens,death=death,kk=kk,u=u)
  list(mat.random, aggregate( perc ~ id, mat.random, mean))
}
# idi: Individual ID
# id: Family ID
# y: random gompertz value
# perc: Observed Survival Percentile
# u: random effect
# kk: number of family members
# cens: survival percentile at right-censoring point
#death: death indicator variable
```

#Process for determining Thresholds when sigma = 0.2 + TH_expmin1
```{r}
set.seed(123)
#Specify parameters for simulating a large dataset with

Sig = 0.2
kvec=c(4,8)
n=c(1000,1000)
sigma=0.2

#Commented code creates a large life-table from which imputed expected survival
#percentiles can be drawn. This is necessary when dealing with right-censored
#observations in the LRC and mLRC scores

data_sig_expmin1<-as.data.frame(Percentile.data_u(n,kvec,sigma)[1])
rml_sig_expmin1<-c()
perc_sort_sig_expmin1<-sort(data_sig_expmin1$perc)
for (i in 1: length(perc_sort_sig_expmin1)){
  rml_sig_expmin1[i]<-mean(perc_sort_sig_expmin1[i:length(perc_sort_sig_expmin1)])
}

lifetable_sig_expmin1<-data.frame(perc=perc_sort_sig_expmin1,expectedy=rml_sig_expmin1)
save(lifetable_sig_expmin1, file = 'lifetable_sig_expmin1.rdata')
#CORRECT BETA_TH Threshold
# y at 85th percentile becomes threshold

TH_sig_expmin1 <- quantile(lifetable_sig_expmin1$perc,0.85)
TH_sig_expmin1

```

